[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hello there!",
    "section": "",
    "text": "I’m a PhD student in The Department of Bioresource Engineering part of the Faculty of Agricultural and Environmental Sciences of McGill University in Canada. I got my B.S. in Civil Engineering, and my M.S. in Civil and Environmental Engineering from Shahid Beheshti University Faculty of Civil, Water and Environmental Engineering. After graduating, I tested designed novel waste technologies to re-use of saline waste to tackle water scarcity and food security in my home country of Iran. Since then, I have shifted away from conventional engineering solutions towards system analysis of the underlying social and political drivers of environmental change. My current research focus is on how human society, specifically urban areas, interact with their environment and metabolize socio-ecological flows and co-evolve.\nI have professional experiences as an engineer in Dorriz company, as a sustainability researcher in Iran Department of Environment, and lately as geospatial data scientist in Aurecon Australia, and data analytics consultant in Global Alliance for Improved Nutrition."
  },
  {
    "objectID": "blog/2024/complex survey design/index.html",
    "href": "blog/2024/complex survey design/index.html",
    "title": "Statistical analysis for weighted data",
    "section": "",
    "text": "This document explains the detailed analysis of Nigeria DQQ survey data. Nigeria DQQ survey study was conducted to address some of the gaps in diet quality data in Nigeria, by assessing diet quality at state level using the DQQ. The specific objectives of the study were to: 1. Measure MDD-W, NCDs-Protect, NCDs-Risk, and GDR scores, and All-5 at state level using the DQQ02 and describe state level diet quality. 2. Compare diet quality of men and women and of urban and rural dwellers. 3. Determine food access at state level."
  },
  {
    "objectID": "blog/2024/complex survey design/index.html#introduction",
    "href": "blog/2024/complex survey design/index.html#introduction",
    "title": "Statistical analysis for weighted data",
    "section": "",
    "text": "This document explains the detailed analysis of Nigeria DQQ survey data. Nigeria DQQ survey study was conducted to address some of the gaps in diet quality data in Nigeria, by assessing diet quality at state level using the DQQ. The specific objectives of the study were to: 1. Measure MDD-W, NCDs-Protect, NCDs-Risk, and GDR scores, and All-5 at state level using the DQQ02 and describe state level diet quality. 2. Compare diet quality of men and women and of urban and rural dwellers. 3. Determine food access at state level."
  },
  {
    "objectID": "blog/2024/complex survey design/index.html#a-quick-look-into-the-metadata",
    "href": "blog/2024/complex survey design/index.html#a-quick-look-into-the-metadata",
    "title": "Statistical analysis for weighted data",
    "section": "A quick look into the metadata",
    "text": "A quick look into the metadata\nLet’s jump straight into the analysis workflow for survey data in R environment. We can use functions from R packages sjPlot, surveytoolbox, and labelled to explore and extract information from the SPSS, SAS and STATA data files. Specifically, view_df function from sjPlot is a quick and efficient way to overview variable ID number, name, label, type and associated value labels.\nFirst, we need to load all required libraries into our working environment in R\n\nCode```{r}\n#| label: Loading required libraries\n#| warning: false\n#| output: false\n#| include: true\n#| code-fold: true\n\n#install.packages(\"sjPlot\")\n#install.packages(\"devtools\")\n#devtools::install_github(\"martinctc/surveytoolbox\")\n\nlibrary(haven)\nlibrary(expss)\nlibrary(tidyverse)\nlibrary(foreign)\nlibrary(survey)\nlibrary(plotrix)\nlibrary(labelled)\nlibrary(surveytoolbox)\nlibrary(sjPlot)\nlibrary(camcorder)\nlibrary(sysfonts)\nlibrary(showtext)\n```\n\n\n\nCode```{r}\n#| include: true\n#| output: true\n#| code-fold: true\n#| warning: false\n\nfile_path &lt;- \"input/Nigeria DQQ Survey HH & Indiv Data Merged.dta\"\nd &lt;- read_dta(file_path)\n```\n\n\nChecking metadata in a clean table for i4 and i3 variables.\n\nCode```{r}\n#| code-fold: true\n#| warning: false\n\nd %&gt;%\n  select(i4, i3) %&gt;%\n  sjPlot::view_df(\n  alternate.rows = T,\n  CSS = list(css.table = \"border: 2px solid;\",\n                   css.tdata = \"border: 1px solid;\",\n                   css.arc = \"color:blue;\"),\n  \n)\n```\n\n\nData frame: .\n\n\n\n\n\n\n\n\n\nID\nName\nLabel\nValues\nValue Labels\n\n\n1\ni4\nSector of Main Job\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n12\n98\n99\nNot working and didn't work in last 12 months\nProfessional, Technical and Related Workers\nAdministrative and Managerial Workers\nOffice and Administrative support workers\nSales and Related Workers\nService Workers\nInstallations, Maintenance and Repair Workers\nCraft and related trade workers\nAgricultural, Animal Husbandry, and Forestry Workers, Fishermen and Hunters\nProduction, Construction and Extractions Workers\nElementary occupations\nOthers (Specify)\nDon’t know\n\n\n2\ni3\nHighest Level of school completed\n1\n2\n3\n4\n5\n98\n99\nNone\nPrimary\nJunior Secondary School\nSenior Secondary School\nHigher / university/ college\nOthers (Specify)\nDON’T KNOW"
  },
  {
    "objectID": "blog/2024/complex survey design/index.html#data-cleaning-and-preparation",
    "href": "blog/2024/complex survey design/index.html#data-cleaning-and-preparation",
    "title": "Statistical analysis for weighted data",
    "section": "Data cleaning and preparation",
    "text": "Data cleaning and preparation\nThe first data cleaning step is to change some names in DQQ variables and make them easier to use for further analysis. Arbitrary function varname is created to manipulate only main DQQ variables’ names.\n\nCode```{r}\n#| output: true\n#| code-fold: true\n#| warning: false\n\nvarname &lt;- function(txt) {\n  ifelse(\n   txt %in% c(\"DQQ_06_1_Green_leafy_vegetables\", \n              \"DQQ_06_2_Green_leafy_vegetables\", \n              \"DQQ_10_1_Other_fruits\",\n              \"DQQ_10_2_Other_fruits\"),\n    gsub(\"^(.*)(.)$\", \"\\\\1_\\\\2\", gsub(\"_\", \"\", substr(txt, 1, 8))),\n    gsub(\"_\", \"\", substr(txt, 1, 6))\n  )\n}\n\nd %&lt;&gt;%\n  rename_with(.fn = varname, .cols = starts_with(\"DQQ_\", ignore.case = FALSE))\n```\n\n\nCheck first five rows for first 5 DQQ values only.\n\nCode```{r}\n#| code-fold: true\n#| warning: false\n\nd %&gt;%\n  select(DQQ01:DQQ05) %&gt;%\n  head()\n```\n\n# A tibble: 6 × 5\n  DQQ01 DQQ02 DQQ03 DQQ04 DQQ05\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1     0     0     1     0\n2     1     1     1     1     0\n3     1     0     0     1     0\n4     1     1     1     1     0\n5     1     0     0     0     0\n6     1     0     1     1     0"
  },
  {
    "objectID": "blog/2024/complex survey design/index.html#main-calculation-code-blocks-for-food-groups",
    "href": "blog/2024/complex survey design/index.html#main-calculation-code-blocks-for-food-groups",
    "title": "Statistical analysis for weighted data",
    "section": "Main calculation code blocks for food groups",
    "text": "Main calculation code blocks for food groups\nTwo core R functions are employed for calculation of food groups. These are case_when function from dplyr to distinguishes between yes and no answers, and ifelse base R for cases when a cumulative score should be evaluated against a threshold (For instance, for MDD-W and its threshold on DDS = 5)\n\nCode```{r}\n#| output: true\n#| code-fold: true\n#| warning: false\n\n# DDS\nd %&lt;&gt;% \n  mutate(\n    dds = \n      case_when(DQQ01 == 0 & DQQ02 == 0 & DQQ03 == 0 ~ 0L, DQQ01 == 1 | DQQ02 == 1 | DQQ03 == 1 ~ 1L, TRUE ~ NA) + \n      case_when(DQQ04 == 0 ~ 0L, DQQ04 == 1 ~ 1L, TRUE ~ NA) + \n      case_when(DQQ21 == 0 ~ 0L, DQQ21 == 1 ~ 1L, TRUE ~ NA) + \n      case_when(DQQ14 == 0 & DQQ15 == 0 & DQQ25 == 0 ~ 0L, DQQ14 == 1 | DQQ15 == 1 | DQQ25 == 1 ~ 1L, TRUE ~ NA) + \n      case_when(DQQ16 == 0 & DQQ17 == 0 & DQQ18 == 0 & DQQ19 == 0 & DQQ20 == 0 ~ 0L, DQQ16 == 1 | DQQ17 == 1 | \n                  DQQ18 == 1 | DQQ19 == 1 | DQQ20 == 1 ~ 1L, TRUE ~ NA) + \n      case_when(DQQ13 == 0 ~ 0L, DQQ13 == 1 ~ 1L, TRUE ~ NA) + \n      case_when(DQQ06_1 == 0 & DQQ06_2 == 0 ~ 0L, DQQ06_1 == 1 | DQQ06_2 == 1 ~ 1L, TRUE ~ NA) + \n      case_when(DQQ05 == 0 & DQQ08 == 0 ~ 0L, DQQ05 == 1 | DQQ08 == 1 ~ 1L, TRUE ~ NA) + \n      case_when(DQQ07 == 0 ~ 0L, DQQ07 == 1 ~ 1L, TRUE ~ NA) + \n      case_when(DQQ09 == 0 & DQQ10_1 == 0 & DQQ10_2 == 0 ~ 0L, DQQ09 == 1 | DQQ10_1 == 1 | DQQ10_2 == 1 ~ 1L, TRUE ~ NA)\n  )\n\n#MDD-W \nd$mddw &lt;- ifelse((case_when(d$DQQ01 == 0 & d$DQQ02 == 0 & d$DQQ03 == 0 ~ 0L, d$DQQ01 == 1 | \n                              d$DQQ02 == 1 | d$DQQ03 == 1 ~ 1L, TRUE ~ NA) + \n                    case_when(d$DQQ04 == 0 ~ 0L, d$DQQ04 == 1 ~ 1L, TRUE ~ NA) + \n                    case_when(d$DQQ21 == 0 ~ 0L, d$DQQ21 == 1 ~ 1L, TRUE ~ NA) + \n                    case_when(d$DQQ14 == 0 & d$DQQ15 == 0 & d$DQQ25 == 0 ~ 0L, d$DQQ14 == 1 | d$DQQ15 == 1 | \n                                d$DQQ25 == 1 ~ 1L, TRUE ~ NA) + \n                    case_when(d$DQQ16 == 0 & d$DQQ17 == 0 & d$DQQ18 == 0 & d$DQQ19 == 0 & d$DQQ20 == 0 ~ 0L, \n                              d$DQQ16 == 1 | d$DQQ17 == 1 | d$DQQ18 == 1 | d$DQQ19 == 1 | d$DQQ20 == 1 ~ 1L, TRUE ~ NA) + \n                    case_when(d$DQQ13 == 0 ~ 0L, d$DQQ13 == 1 ~ 1L, TRUE ~ NA) + \n                    case_when(d$DQQ06_1 == 0 & d$DQQ06_2 == 0 ~ 0L, d$DQQ06_1 == 1 | d$DQQ06_2 == 1 ~ 1L, TRUE ~ NA) + \n                    case_when(d$DQQ05 == 0 & d$DQQ08 == 0 ~ 0L, d$DQQ05 == 1 | d$DQQ08 == 1 ~ 1L, TRUE ~ NA) + \n                    case_when(d$DQQ07 == 0 ~ 0L, d$DQQ07 == 1 ~ 1L, TRUE ~ NA) + \n                    case_when(d$DQQ09 == 0 & d$DQQ10_1 == 0 & d$DQQ10_2 == 0 ~ 0L, d$DQQ09 == 1 | d$DQQ10_1 == 1 | \n                                d$DQQ10_2 == 1 ~ 1L, TRUE ~ NA)) &gt;= 5 & d$gender == 0 &  d$hr5 &gt;= 15 & d$hr5 &lt;= 49, 1, \n                 \n                 ifelse((case_when(d$DQQ01 == 0 & d$DQQ02 == 0 & d$DQQ03 == 0 ~ 0L, d$DQQ01 == 1 | d$DQQ02 == 1 | \n                                     d$DQQ03 == 1 ~ 1L, TRUE ~ NA) + \n                           case_when(d$DQQ04 == 0 ~ 0L, d$DQQ04 == 1 ~ 1L, TRUE ~ NA) + \n                           case_when(d$DQQ21 == 0 ~ 0L, d$DQQ21 == 1 ~ 1L, TRUE ~ NA) + \n                           case_when(d$DQQ14 == 0 & d$DQQ15 == 0 & d$DQQ25 == 0 ~ 0L, d$DQQ14 == 1 | d$DQQ15 == 1 | \n                                       d$DQQ25 == 1 ~ 1L, TRUE ~ NA) + \n                           case_when(d$DQQ16 == 0 & d$DQQ17 == 0 & d$DQQ18 == 0 & d$DQQ19 == 0 & d$DQQ20 == 0 ~ 0L, \n                                     d$DQQ16 == 1 | d$DQQ17 == 1 | d$DQQ18 == 1 | d$DQQ19 == 1 | d$DQQ20 == 1 ~ 1L, TRUE ~ NA) + \n                           case_when(d$DQQ13 == 0 ~ 0L, d$DQQ13 == 1 ~ 1L, TRUE ~ NA) + \n                           case_when(d$DQQ06_1 == 0 & d$DQQ06_2 == 0 ~ 0L, d$DQQ06_1 == 1 | d$DQQ06_2 == 1 ~ 1L, TRUE ~ NA) + \n                           case_when(d$DQQ05 == 0 & d$DQQ08 == 0 ~ 0L, d$DQQ05 == 1 | d$DQQ08 == 1 ~ 1L, TRUE ~ NA) + \n                           case_when(d$DQQ07 == 0 ~ 0L, d$DQQ07 == 1 ~ 1L, TRUE ~ NA) + \n                           case_when(d$DQQ09 == 0 & d$DQQ10_1 == 0 & d$DQQ10_2 == 0 ~ 0L, d$DQQ09 == 1 | d$DQQ10_1 == 1 | \n                                       d$DQQ10_2 == 1 ~ 1L, TRUE ~ NA)) &lt; 5 & d$gender == 0 &  d$hr5 &gt;= 15 & d$hr5 &lt;= 49, 0, NA)) \n\n#All-5  ----\nd$all5 &lt;- ifelse((\n  case_when(d$DQQ01 == 0 & d$DQQ02 == 0 & d$DQQ03 == 0 ~ 0L, d$DQQ01 == 1 | \n              d$DQQ02 == 1 | d$DQQ03 == 1 ~ 1L, TRUE ~ NA) +\n    case_when(d$DQQ05 == 0 & d$DQQ06_1 == 0 & d$DQQ06_2 == 0 & d$DQQ07 == 0 ~ 0L, \n              d$DQQ05 == 1 | d$DQQ06_1 == 1 | d$DQQ06_2 == 1 | d$DQQ07 == 1 ~ 1L, TRUE ~ NA) + \n    case_when(d$DQQ08 == 0 & d$DQQ09 == 0 & d$DQQ10_1 == 0 & d$DQQ10_2 == 0 ~ 0L, \n              d$DQQ08 == 1 | d$DQQ09 == 1 | d$DQQ10_1 == 1 | d$DQQ10_2 == 1 ~ 1L, TRUE ~ NA) + \n    case_when(d$DQQ04 == 0 & d$DQQ21 == 0 ~ 0L, d$DQQ04 == 1 | d$DQQ21 == 1 ~ 1L, TRUE ~ NA) +\n    case_when(d$DQQ13 == 0 & d$DQQ14 == 0 & d$DQQ15 == 0 & d$DQQ16 == 0 & d$DQQ17 == 0 & \n                d$DQQ18 == 0 & d$DQQ19 == 0 & d$DQQ20 == 0 & d$DQQ25 == 0 ~ 0L, \n              d$DQQ13 == 1 | d$DQQ14 == 1 | d$DQQ15 == 1 | d$DQQ16 == 1 | d$DQQ17 == 1 | \n                d$DQQ18 == 1 | d$DQQ19 == 1 | d$DQQ20 == 1 | d$DQQ25 == 1 ~ 1L, TRUE ~ NA)) == 5, 1, 0)\n\n#At least one vegetable  ----\nd %&lt;&gt;% mutate(\n  all5a = case_when(DQQ05 == 0 & DQQ06_1 == 0 & DQQ06_2 == 0 & DQQ07 == 0 ~ 0L, \n                    DQQ05 == 1 | DQQ06_1 == 1 | DQQ06_2 == 1 | DQQ07 == 1 ~ 1L, TRUE ~ NA)\n)\n\n#At least one fruit  ----\nd %&lt;&gt;% mutate(\n  all5b = case_when(DQQ08 == 0 & DQQ09 == 0 & DQQ10_1 == 0 & DQQ10_2 == 0 ~ 0L, \n                    DQQ08 == 1 | DQQ09 == 1 | DQQ10_1 == 1 | DQQ10_2 == 1 ~ 1L, TRUE ~ NA)\n)\n\n#At least one pulse, nut or seed  ----\nd %&lt;&gt;% mutate(\n  all5c = case_when(DQQ04 == 0 & DQQ21 == 0 ~ 0L, DQQ04 == 1 | DQQ21 == 1 ~ 1L, TRUE ~ NA)\n)\n\n#At least one animal-source food (ASF)  ----\nd %&lt;&gt;% mutate(\n  all5d = case_when(DQQ13 == 0 & DQQ14 == 0 & DQQ15 == 0 & DQQ16 == 0 & DQQ17 == 0 & \n                      DQQ18 == 0 & DQQ19 == 0 & DQQ20 == 0 & DQQ25 == 0 ~ 0L, \n                    DQQ13 == 1 | DQQ14 == 1 | DQQ15 == 1 | DQQ16 == 1 | DQQ17 == 1 | \n                      DQQ18 == 1 | DQQ19 == 1 | DQQ20 == 1 | DQQ25 == 1 ~ 1L, TRUE ~ NA)\n)\n\n#At least starchy staple  ----\nd %&lt;&gt;% mutate(\n  all5e = case_when(DQQ01 == 0 & DQQ02 == 0 & DQQ03 == 0 ~ 0L, DQQ01 == 1 \n                    | DQQ02 == 1 | DQQ03 == 1 ~ 1L, TRUE ~ NA)\n)\n\n#NCD-Protect score  ----\nd %&lt;&gt;%\n  mutate(\n    ncdp = \n      case_when(DQQ02 == 0 ~ 0L, DQQ02 == 1 ~ 1L, TRUE ~ NA) + \n      case_when(DQQ04 == 0 ~ 0L, DQQ04 == 1 ~ 1L, TRUE ~ NA) + \n      case_when(DQQ21 == 0 ~ 0L, DQQ21 == 1 ~ 1L, TRUE ~ NA) + \n      case_when(DQQ05 == 0 ~ 0L, DQQ05 == 1 ~ 1L, TRUE ~ NA) + \n      case_when(DQQ06_1 == 0 & DQQ06_2 == 0 ~ 0L, DQQ06_1 == 1 | \n                  DQQ06_2 == 1 ~ 1L, TRUE ~ NA) + \n      case_when(DQQ07 == 0 ~ 0L, DQQ07 == 1 ~ 1L, TRUE ~ NA) + \n      case_when(DQQ08 == 0 ~ 0L, DQQ08 == 1 ~ 1L, TRUE ~ NA) + \n      case_when(DQQ09 == 0 ~ 0L, DQQ09 == 1 ~ 1L, TRUE ~ NA) + \n      case_when(DQQ10_1 == 0 & DQQ10_2 == 0 ~ 0L, DQQ10_1 == 1 |\n                  DQQ10_2 == 1 ~ 1L, TRUE ~ NA)\n  )\n\n#NCD-Risk score  ----\nd %&lt;&gt;%\n  mutate(\n    ncdr = \n      case_when(DQQ28 == 0 ~ 0L, DQQ28 == 1 ~ 1L, TRUE ~ NA) + \n      case_when(DQQ11 == 0 ~ 0L, DQQ11 == 1 ~ 1L, TRUE ~ NA) + \n      case_when(DQQ12 == 0 ~ 0L, DQQ12 == 1 ~ 1L, TRUE ~ NA) + \n      case_when(DQQ16 == 0 ~ 0L, DQQ16 == 1 ~ 1L, TRUE ~ NA) + \n      case_when(DQQ16 == 0 ~ 0L, DQQ16 == 1 ~ 1L, TRUE ~ NA) + \n      case_when(DQQ17 == 0 & DQQ18 == 0 ~ 0L, DQQ17 == 1 | \n                  DQQ18 == 1 ~ 1L, TRUE ~ NA) + \n      case_when(DQQ24 == 0 ~ 0L, DQQ24 == 1 ~ 1L, TRUE ~ NA) + \n      case_when(DQQ23 == 0 & DQQ29 == 0 ~ 0L, DQQ23 == 1 | \n                  DQQ29 == 1 ~ 1L, TRUE ~ NA) + \n      case_when(DQQ22 == 0 ~ 0L, DQQ22 == 1 ~ 1L, TRUE ~ NA) \n  )\n\n#GDR score  ----\nd %&lt;&gt;%\n  mutate(\n    gdr = \n      case_when(DQQ02 == 0 ~ 0L, DQQ02 == 1 ~ 1L, TRUE ~ NA) + \n      case_when(DQQ04 == 0 ~ 0L, DQQ04 == 1 ~ 1L, TRUE ~ NA) + \n      case_when(DQQ21 == 0 ~ 0L, DQQ21 == 1 ~ 1L, TRUE ~ NA) + \n      case_when(DQQ05 == 0 ~ 0L, DQQ05 == 1 ~ 1L, TRUE ~ NA) + \n      case_when(DQQ06_1 == 0 & DQQ06_2 == 0 ~ 0L, DQQ06_1 == 1 | \n                  DQQ06_2 == 1 ~ 1L, TRUE ~ NA) + \n      case_when(DQQ07 == 0 ~ 0L, DQQ07 == 1 ~ 1L, TRUE ~ NA) + \n      case_when(DQQ08 == 0 ~ 0L, DQQ08 == 1 ~ 1L, TRUE ~ NA) + \n      case_when(DQQ09 == 0 ~ 0L, DQQ09 == 1 ~ 1L, TRUE ~ NA) + \n      case_when(DQQ10_1 == 0 & DQQ10_2 == 0 ~ 0L, DQQ10_1 == 1 | \n                  DQQ10_2 == 1 ~ 1L, TRUE ~ NA) -\n      case_when(DQQ28 == 0 ~ 0L, DQQ28 == 1 ~ 1L, TRUE ~ NA) - \n      case_when(DQQ11 == 0 ~ 0L, DQQ11 == 1 ~ 1L, TRUE ~ NA) - \n      case_when(DQQ12 == 0 ~ 0L, DQQ12 == 1 ~ 1L, TRUE ~ NA) - \n      case_when(DQQ16 == 0 ~ 0L, DQQ16 == 1 ~ 1L, TRUE ~ NA) - \n      case_when(DQQ16 == 0 ~ 0L, DQQ16 == 1 ~ 1L, TRUE ~ NA) - \n      case_when(DQQ17 == 0 & DQQ18 == 0 ~ 0L, DQQ17 == 1 | \n                  DQQ18 == 1 ~ 1L, TRUE ~ NA) - \n      case_when(DQQ24 == 0 ~ 0L, DQQ24 == 1 ~ 1L, TRUE ~ NA) - \n      case_when(DQQ23 == 0 & DQQ29 == 0 ~ 0L, DQQ23 == 1 | \n                  DQQ29 == 1 ~ 1L, TRUE ~ NA) - \n      case_when(DQQ22 == 0 ~ 0L, DQQ22 == 1 ~ 1L, TRUE ~ NA) + \n      9\n  )\n\n#DQQ score  ----\n  #Not applicable for this stage\n\n#Zero vegetable or fruit   ----\nd %&lt;&gt;% mutate(\n  zvegfr = case_when(DQQ05 == 0 & DQQ06_1 == 0 & DQQ06_2 == 0 \n                     & DQQ07 == 0 | DQQ08 == 0 & DQQ09 == 0 & DQQ10_1 == 0 & DQQ10_2 == 0 ~ 1L, \n                     DQQ05 == 1 | DQQ06_1 == 1 | DQQ06_2 == 1 | \n                       DQQ07 == 1 | DQQ08 == 1 | DQQ09 == 1 | DQQ10_1 == 1 | DQQ10_2 == 1 ~ 0L, TRUE ~ NA)\n)\n\n#ASF consumption ----\nd %&lt;&gt;% mutate(\n  asf = case_when(DQQ13 == 0 & DQQ14 == 0 & DQQ15 == 0 & DQQ17 == 0 & \n                    DQQ18 == 0 & DQQ19 == 0 & DQQ20 == 0 & DQQ25 == 0 ~ 0L, \n                  DQQ13 == 1 | DQQ14 == 1 | DQQ15 == 1 | DQQ17 == 1 | \n                    DQQ18 == 1 | DQQ19 == 1 | DQQ20 == 1 | DQQ25 == 1 ~ 1L, TRUE ~ NA)\n)\n\n#Sweet beverage ----\nd %&lt;&gt;% mutate(\n  swtbev = case_when(DQQ26 == 0 & DQQ27 == 0 & DQQ28 == 0 ~ 0L, \n                     DQQ26 == 1 | DQQ27 == 1 | DQQ28 == 1 ~ 1L, TRUE ~ NA)\n)\n\n#Soft drink consumption  ----\nd %&lt;&gt;% mutate(\n  sofdr = case_when(DQQ28 == 0 ~ 0L, DQQ28 == 1 ~ 1L, TRUE ~ NA)\n)\n\n#Sweet foods consumption   ----\nd %&lt;&gt;% mutate(\n  swtfd = case_when(DQQ11 == 0 & DQQ12 == 0 ~ 0L, \n                    DQQ11 == 1 | DQQ12 == 1 ~ 1L, TRUE ~ NA) \n)\n\n#Salty or fried snack consumption   ----\nd %&lt;&gt;% mutate(\n  safd = case_when(DQQ22 == 0 & DQQ23 == 0 & DQQ24 == 0 ~ 0L, \n                   DQQ22 == 1 | DQQ23 == 1 | DQQ24 == 1 ~ 1L, TRUE ~ NA)\n)\n\n#Whole grain consumption   ----\nd %&lt;&gt;% mutate(\n  wgrn = case_when(DQQ02 == 0 ~ 0L, DQQ02 == 1 ~ 1L, TRUE ~ NA)\n)\n\n#Pulse consumption   ----\nd %&lt;&gt;% mutate(\n  pls = case_when(DQQ04 == 0 ~ 0L, DQQ04 == 1 ~ 1L, TRUE ~ NA)\n)\n\n#Nuts and seeds consumption   ----\nd %&lt;&gt;% mutate(\n  nut = case_when(DQQ21 == 0 ~ 0L, DQQ21 == 1 ~ 1L, TRUE ~ NA)\n)\n\n#Processed meat consumption   ----\nd %&lt;&gt;% mutate(\n  pmeat = case_when(DQQ16 == 0 ~ 0L, DQQ16 == 1 ~ 1L, TRUE ~ NA)\n)\n\n#Percent consuming each food group   ----\n#a. at least one vegetable or fruit   ----\nd %&lt;&gt;% mutate(\n  vegfr = case_when(DQQ05 == 0 & DQQ06_1 == 0 & DQQ06_2 == 0 & \n                      DQQ07 == 0 & DQQ08 == 0 & DQQ09 == 0 & DQQ10_1 == 0 & DQQ10_2 == 0 ~ 0L, \n                    DQQ05 == 1 | DQQ06_1 == 1 | DQQ06_2 == 1 | \n                      DQQ07 == 1 | DQQ08 == 1 | DQQ09 == 1 | DQQ10_1 == 1 | DQQ10_2 == 1 ~ 1L, TRUE ~ NA)\n)\n\n#b. Salty snacks, instant noodles, or fast food  ----\nd %&lt;&gt;% mutate(\n  snf = case_when(DQQ22 == 0 & DQQ23 == 0 & DQQ29 == 0 ~ 0L, \n                  DQQ22 == 1 | DQQ23 == 1 | DQQ29 == 1 ~ 1L, TRUE ~ NA)\n)\n\n#ome complementary indicators ----\n#Dairy ----\nd %&lt;&gt;% mutate(\n  dairy = case_when(DQQ14 == 0 & DQQ15 == 0 & DQQ25 == 0 ~ 0L, \n                    DQQ14 == 1 | DQQ15 == 1 | DQQ25 == 1 ~ 1L, TRUE ~ NA)\n)\n\n#Dark green leafy vegetables ----\nd %&lt;&gt;% mutate(\n  dveg = case_when(DQQ06_1 == 0 & DQQ06_2 == 0 ~ 0L, \n                   DQQ06_1 == 1 | DQQ06_2 == 1 ~ 1L, TRUE ~ NA)\n)\n\n#Meat, poultry, or fish ----\nd %&lt;&gt;% mutate(\n  anml = case_when(DQQ16 == 0 & DQQ17 == 0 & DQQ18 == 0 & \n                     DQQ19 == 0 & DQQ20 == 0 ~ 0L, \n                   DQQ16 == 1 | DQQ17 == 1 | DQQ18 == 1 | \n                     DQQ19 == 1 | DQQ20 == 1 ~ 1L, TRUE ~ NA)\n)\n\n#Other fruits ----\nd %&lt;&gt;% mutate(\n  ofr = case_when(DQQ10_1 == 0 & DQQ10_2 == 0 ~ 0L, \n                  DQQ10_1 == 1 | DQQ10_2 == 1 ~ 1L, TRUE ~ NA) \n)\n\n#Other vegetables ----\nd %&lt;&gt;% mutate(\n  oveg = case_when(DQQ07 == 0 ~ 0L, \n                   DQQ07 == 1 ~ 1L, TRUE ~ NA)\n)\n\n#Salty snacks, instant noodles, or fast food (including deep fried) ----\nd %&lt;&gt;% mutate(\n  snfd = case_when(DQQ22 == 0 & DQQ23 == 0 & DQQ24 == 0 & DQQ29 == 0 ~ 0L, \n                   DQQ22 == 1 | DQQ23 == 1 | DQQ24 == 1 | DQQ29 == 0 ~ 1L, TRUE ~ NA)\n)\n\n#Unprocessed red meat ----\nd %&lt;&gt;% mutate(\n  umeat = case_when(DQQ17 == 0 & DQQ18 == 0 ~ 0L, \n                    DQQ17 == 1 | DQQ18 == 1 ~ 1L, TRUE ~ NA) \n)\n\nd %&gt;%\n  select(dds, mddw, all5, ncdp, ncdr, gdr, sofdr) %&gt;%\n  head()\n```\n\n# A tibble: 6 × 7\n    dds  mddw  all5  ncdp  ncdr   gdr sofdr\n  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt;\n1     8     1     1     5     2    12     0\n2     8     1     1     6     1    14     0\n3     8    NA     1     5     1    13     0\n4     8    NA     1     6     1    14     0\n5     6    NA     0     3     3     9     1\n6     7     1     0     4     5     8     1\n\n\nWhen reading a data set using haven, variables have labels and other metadata attached as attributes. If a variable contains labelled values it will be imported as a haven_labelled vector, which stores the variable labels in the labels attribute. First use class and head functions to see value labels and then check for any missing values in i3 and i4 which are job and education classification variables.\nThan we can use add_labels from sjlabelled package to replace value labels with shorter ones, and then factorizing and ordering them based on their original order.\n\nCode```{r}\n#| output: false\n#| code-fold: true\n#| warning: false\n\n# Checking format and value labels\nclass(d$i4)\nhead(d$i4)\n\n# Check for missing values\nd %&gt;% count(i4, is.na(i4)) # job sector \nd %&gt;% count(i3, is.na(i3)) # level of education\n\n# There is an undefined value in education level. \ntable(labelled::to_factor(d$i3))\n\n#Lets call it undefined category for now.\nd$i3 &lt;- sjlabelled::add_labels(d$i3, labels = c(\n  `Junior Secondary` = 3,\n  `Senior Secondary` = 4,\n  `Higher Education` = 5,\n  `Undefined` = 6)\n  )\n\nd$i4 &lt;- sjlabelled::add_labels(\n  d$i4, labels = c(\n  \"Not working\" = 1,\n  \"Professional and Technical\" = 2,\n  \"Administrative and Managerial\" = 3,\n  \"Office and Admin\" = 4,\n  \"Sales\" = 5,\n  \"Service\" = 6,\n  \"Installations and Maintenance\" = 7 ,\n  \"Craft and Trade\" = 8,\n  \"Agriculture and Fishery\" = 9, \n  \"Production and Construction\" = 10,\n  \"Elementary\" = 11,\n  \"Others\" = 12,\n  \"Don’t know\" = 13\n  )\n)\n\n# Convert to factors, using the labels as levels\n# Labels that don’t exist in the data can be dropped from the levels using drop_unused_labels = TRUE.\nd$job &lt;- labelled::to_factor(d$i4, levels = \"labels\", ordered = TRUE, \n                             sort_levels = 'none', decreasing = FALSE, drop_unused_labels = TRUE)\nd$edu &lt;- labelled::to_factor(d$i3, levels = \"labels\", ordered = TRUE, \n                             sort_levels = 'none', decreasing = FALSE, drop_unused_labels = TRUE)\nd$reg &lt;- labelled::to_factor(d$strata, levels = \"labels\", ordered = TRUE, \n                             sort_levels = 'none', decreasing = FALSE, drop_unused_labels = TRUE)\ntable(d$edu)\n\n# Other ways also work\ngender &lt;- fct_collapse(as.factor(d$gender), \"Male\" = \"1\", \"Female\" = \"0\")\nd$gender &lt;- gender\nd$Residence &lt;- ifelse(d$sector == 1, \"Urban\", ifelse(d$sector == 2, \"Rural\", NA)) \n```"
  },
  {
    "objectID": "blog/2024/complex survey design/index.html#complex-survey-design",
    "href": "blog/2024/complex survey design/index.html#complex-survey-design",
    "title": "Statistical analysis for weighted data",
    "section": "Complex survey design",
    "text": "Complex survey design\nHere survey R package is used to create complex design objects based on weights provided by GALLUP.\n\nCode```{r}\n#| warning: false\n#| output: false\n#| code-fold: true\n\noptions(survey.lonely.psu = \"adjust\")\nd &lt;- data.frame(d)\n\nd_m &lt;- d[d$gender == \"Male\", ]\nd_f &lt;- d[d$gender == \"Female\", ]\nd_u &lt;- d[which(d$Residence == \"Urban\"), ]\nd_r &lt;- d[which(d$Residence == \"Rural\"), ]\n\nd_w &lt;- svydesign(ids = ~interview__id, strata = ~strata, nest = FALSE, weights = ~hh_weight, data =  d)\nd_m_w &lt;- svydesign(ids = ~interview__id, strata = ~strata, nest = FALSE, weights = ~hh_weight, data = d_m)\nd_f_w &lt;- svydesign(ids = ~interview__id, strata = ~strata, nest = FALSE, weights = ~hh_weight, data = d_f)\nd_u_w &lt;- svydesign(ids = ~interview__id, strata = ~strata, nest = FALSE, weights = ~hh_weight, data = d_u)\nd_r_w &lt;- svydesign(ids = ~interview__id, strata = ~strata, nest = FALSE, weights = ~hh_weight, data = d_r)\n\nresult1 &lt;- setNames(data.frame(matrix(ncol = 9, nrow = 1)), \n                    c(\"Subgroup\", \"Variable\", \"Mean_prevalence\", \"Lower_95_CI\", \"Upper_95_CI\", \"Difference\", \"Diff_LCI\", \"Diff_UCI\", \"Diff_p\"))\nresult2 &lt;- setNames(data.frame(matrix(ncol = 9, nrow = 1)), \n                    c(\"Subgroup\", \"Variable\", \"Mean_prevalence\", \"Lower_95_CI\", \"Upper_95_CI\", \"Difference\", \"Diff_LCI\", \"Diff_UCI\", \"Diff_p\"))\n\nfor(i in c(\"dds\", \"ncdp\", \"ncdr\", \"gdr\")){\n      x &lt;- svymean(~d[, i], d_w, na.rm = TRUE, method = \"as\", df=degf(d_w))\n      x_LCI &lt;- confint(x)[1]\n      x_UCI &lt;- confint(x)[2]\n      result1 &lt;- rbind(result1, c(\"All\", \n                                  i,\n                                  round(x, digits = 2), \n                                  round(x_LCI, digits = 2), \n                                  round(x_UCI, digits = 2), NA, NA, NA, NA))\n      #  # Male\n      x &lt;- svymean(~d_m[, i],  d_m_w, na.rm = TRUE, method = \"as\", df=degf(d_m_w))\n      x_LCI &lt;- confint(x)[1]\n      x_UCI &lt;- confint(x)[2]\n      varname &lt;- as.name(i)\n      t &lt;- eval(bquote(svyttest(.(varname)~gender, d_w)))\n      result1 &lt;- rbind(result1, c(\"Male\", \n                                  i, \n                                  round(x, digits = 2), \n                                  round(x_LCI, digits = 2), \n                                  round(x_UCI, digits = 2),\n                                  as.numeric(round(t$estimate, digits = 2)), \n                                  as.numeric(round(t$conf.int[1], digits = 2)), \n                                  as.numeric(round(t$conf.int[2], digits = 2)), \n                                  as.numeric(round(t$p.value, digits = 2))))\n      \n      #  # Female\n      x &lt;- svymean(~d_f[, i],  d_f_w, na.rm = TRUE, method = \"as\", df=degf(d_f_w))\n      x_LCI &lt;- confint(x)[1]\n      x_UCI &lt;- confint(x)[2]\n      result1 &lt;- rbind(result1, c(\"Female\", \n                                  i,\n                                  round(x, digits = 2), \n                                  round(x_LCI, digits = 2), \n                                  round(x_UCI, digits = 2),\n                                  as.numeric(round(t$estimate, digits = 2)), \n                                  as.numeric(round(t$conf.int[1], digits = 2)), \n                                  as.numeric(round(t$conf.int[2], digits = 2)), \n                                  as.numeric(round(t$p.value, digits = 2))))\n      \n      #  # Urban\n      x &lt;- svymean(~d_u[, i],  d_u_w, na.rm = TRUE, method = \"as\", df=degf(d_u_w))\n      x_LCI &lt;- confint(x)[1]\n      x_UCI &lt;- confint(x)[2]\n      varname &lt;- as.name(i)\n      t &lt;- eval(bquote(svyttest(.(varname)~Residence, d_w)))\n      result1 &lt;- rbind(result1, c(\"Urban\", \n                                  i,\n                                  round(x, digits = 2), \n                                  round(x_LCI, digits = 2), \n                                  round(x_UCI, digits = 2),\n                                  as.numeric(round(t$estimate, digits = 2)), \n                                  as.numeric(round(t$conf.int[1], digits = 2)), \n                                  as.numeric(round(t$conf.int[2], digits = 2)), \n                                  as.numeric(round(t$p.value, digits = 2))))\n      \n      #  # Rural\n      x &lt;- svymean(~d_r[, i],  d_r_w, na.rm = TRUE, method = \"as\", df=degf(d_r_w))\n      x_LCI &lt;- confint(x)[1]\n      x_UCI &lt;- confint(x)[2]\n      result1 &lt;- rbind(result1, c(\"Rural\", \n                                  i,\n                                  round(x, digits = 2), \n                                  round(x_LCI, digits = 2), \n                                  round(x_UCI, digits = 2),\n                                  as.numeric(round(t$estimate, digits = 2)), \n                                  as.numeric(round(t$conf.int[1], digits = 2)), \n                                  as.numeric(round(t$conf.int[2], digits = 2)), \n                                  as.numeric(round(t$p.value, digits = 2))))\n      \n    }\n\n#prevalence\nfor(i in c(\"all5\", \"all5a\", \"all5b\", \"all5c\", \"all5d\", \"all5e\", \"DQQ11\", \"DQQ14\", \"DQQ09\", \"dairy\", \"dveg\", \"DQQ24\", \"DQQ13\", \n               \"DQQ29\", \"DQQ20\", \"DQQ01\", \"DQQ27\", \"DQQ23\", \"mddw\", \"anml\", \"DQQ25\", \"DQQ21\", \"ofr\", \"DQQ12\", \"oveg\", \"DQQ22\", \n               \"DQQ19\", \"DQQ16\", \"DQQ04\", \"safd\", \"snf\", \"swtbev\", \"DQQ28\", \"swtfd\", \"DQQ26\", \"umeat\", \"DQQ18\", \"DQQ17\",\n               \"DQQ08\", \"DQQ05\", \"DQQ03\", \"DQQ02\", \"DQQ15\", \"zvegfr\")){ \n      # All\n      x &lt;- svyciprop(~I(d[, i] == 1), d_w, na.rm = TRUE, method = \"as\", df=degf(d_w))\n      x_LCI &lt;- attributes(x)$ci[1]\n      x_UCI &lt;- attributes(x)$ci[2]\n      result2 &lt;- rbind(result2, c(\"All\", \n                                  i, \n                                  round(x*100, digits = 2), \n                                  round(x_LCI*100, digits = 2), \n                                  round(x_UCI*100, digits = 2), NA, NA, NA, NA))\n      # Male and Female\n      x &lt;- svyciprop(~I(d_m[, i] == 1), d_m_w, na.rm = TRUE, method = \"as\", df=degf(d_m_w))\n      x_LCI &lt;- attributes(x)$ci[1]\n      x_UCI &lt;- attributes(x)$ci[2]\n      \n      y &lt;- svyciprop(~I(d_f[, i] == 1), d_f_w, na.rm = TRUE, method = \"as\", df=degf(d_f_w))\n      y_LCI &lt;- attributes(y)$ci[1]\n      y_UCI &lt;- attributes(y)$ci[2]\n      \n      varname &lt;- as.name(i)\n      ifelse(x == 0 & y == 0, t &lt;- NA, t &lt;- eval(bquote(svychisq(~.(varname)+gender,d_w))))\n      \n      result2 &lt;- rbind(result2, c(\"Male\", \n                                  i, \n                                  round(x*100, digits = 2), \n                                  round(x_LCI*100, digits = 2), \n                                  round(x_UCI*100, digits = 2),\n                                  round((x-y)*100, digits = 2), \n                                  NA, \n                                  NA, \n                                  ifelse(is.na(t), NA, round(as.numeric(t$p.value), digits = 2))))\n      \n      result2 &lt;- rbind(result2, c(\"Female\", \n                                  i, \n                                  round(y*100, digits = 2), \n                                  round(y_LCI*100, digits = 2), \n                                  round(y_UCI*100, digits = 2), \n                                  round((x-y)*100, digits = 2),\n                                  round((x-y)*100, digits = 2), \n                                  NA, \n                                  NA, \n                                  ifelse(is.na(t), NA, round(as.numeric(t$p.value), digits = 2))))\n      \n      # Rural and Urban\n      x &lt;- svyciprop(~I(d_u[, i] == 1), d_u_w, na.rm = TRUE, method = \"as\", df=degf(d_u_w))\n      x_LCI &lt;- attributes(x)$ci[1]\n      x_UCI &lt;- attributes(x)$ci[2]\n      \n      y &lt;- svyciprop(~I(d_r[, i] == 1), d_r_w, na.rm = TRUE, method = \"as\", df=degf(d_r_w))\n      y_LCI &lt;- attributes(y)$ci[1]\n      y_UCI &lt;- attributes(y)$ci[2]\n      \n      varname &lt;- as.name(i)\n      ifelse(x == 0 & y == 0, t &lt;- NA, t &lt;- eval(bquote(svychisq(~.(varname)+Residence,d_w))))\n      \n      result2 &lt;- rbind(result2, c(\"Urban\", \n                                  i,\n                                  round(x*100, digits = 2), \n                                  round(x_LCI*100, digits = 2), \n                                  round(x_UCI*100, digits = 2),\n                                  round((x-y)*100, digits = 2), \n                                  NA, \n                                  NA, \n                                  ifelse(is.na(t), NA, round(as.numeric(t$p.value), digits = 2))))\n      \n      result2 &lt;- rbind(result2, c(\"Rural\", \n                                  i, \n                                  round(y*100, digits = 2), \n                                  round(y_LCI*100, digits = 2), \n                                  round(y_UCI*100, digits = 2),\n                                  round((x-y)*100, digits = 2), \n                                  NA, \n                                  NA, \n                                  ifelse(is.na(t), NA, round(as.numeric(t$p.value), digits = 2))))\n      \n    }    \n\n\nresultlist1 &lt;- c()\nresultlist2 &lt;- c()\nresult1 &lt;- result1[-1,]\nresultlist1 &lt;- c(resultlist1,result1)\nresult2 &lt;- result2[-1,]\nresultlist2 &lt;- c(resultlist2,result2)\nresultlist1 &lt;- data.frame(resultlist1)      \nresultlist2  &lt;- data.frame(resultlist2)\ncolnames(resultlist1) &lt;- colnames(resultlist2)\nresults &lt;- rbind(resultlist1, resultlist2)\nresults &lt;- results %&gt;%\n  mutate(\n    Unit = case_when(Variable %in% c(\"dds\", \"ncdp\", \"ncdr\", \"gdr\") ~ \"Score\",\n                     .default = \"Percentage\")\n  )\n\n# Long Names format\nlongNames &lt;- c(all5 = \"All-5\", \n               all5a = \"At least one vegetable\",\n               all5b = \"At least one fruit\",\n               all5c = \"At least one pulse, nut, or seed\",\n               all5d = \"At least one animal-source food\",\n               all5e = \"At least one starchy staple food\",\n               dds = \"Dietary diversity score\",\n               ncdp = \"NCD-Protect\",\n               ncdr = \"NCD-Risk\",\n               gdr = \"GDR score\",\n               DQQ11 = \"Baked or grain-based sweets\",\n               DQQ14 = \"Cheese\",\n               DQQ09 = \"Citrus\",\n               dairy = \"Dairy\",\n               dveg = \"Dark green leafy vegetables\",\n               DQQ24 = \"Deep fried foods\",\n               DQQ13 = \"Eggs\",\n               DQQ29 = \"Fast food\", \n               DQQ20 = \"Fish or seafood\",\n               DQQ01 = \"Foods made from grains\",\n               DQQ27 = \"Fruit juice and fruit drinks\",\n               DQQ23 = \"Instant noodles\",\n               mddw = \"MDD-W\",\n               anml = \"Meat, poultry, or fish\",\n               DQQ25  = \"Milk\",\n               DQQ21 = \"Nuts or seeds\",\n               ofr = \"Other fruits\",\n               DQQ12 = \"Other sweets\",\n               oveg = \"Other vegetables\",\n               DQQ22 = \"Packaged ultra-processed salty snacks\",\n               DQQ19 = \"Poultry\",\n               DQQ16 = \"Processed meats\",\n               DQQ04  = \"Pulses\",\n               safd = \"Salty or fried snacks\",\n               snf = \"Salty snacks, instant noodles, or fast food\",\n               swtbev = \"Sweet beverages\",\n               DQQ28 = \"Soft drink consumption\",\n               swtfd = \"Sweet foods\",\n               DQQ26  = \"Sweet tea, coffee, or cocoa\",\n               umeat = \"Unprocessed red meat\",\n               DQQ18 = \"Unprocessed red meat (non-ruminants)\",\n               DQQ17 = \"Unprocessed red meat (ruminants)\",\n               DQQ08 = \"Vitamin A-rich fruits\",\n               DQQ05 = \"Vitamin A-rich orange vegetables\",\n               DQQ03 = \"White roots or tubers\",\n               DQQ02  = \"Whole grains\",\n               DQQ15  = \"Yogurt\",\n               zvegfr= \"Zero vegetable or fruit consumption\"\n)\n\n# DQQ names\ndqqNames &lt;- c(DQQ11 = \"DQQ11\",\n              DQQ14 = \"DQQ14\",\n              DQQ09 = \"DQQ9\",\n              dveg = \"DQQ6\",\n              DQQ24 = \"DQQ24\",\n              DQQ13 = \"DQQ13\",\n              DQQ29 = \"DQQ29\", \n              DQQ20 = \"DQQ20\",\n              DQQ01 = \"DQQ1\",\n              DQQ27 = \"DQQ27\",\n              DQQ23 = \"DQQ23\",\n              DQQ25  = \"DQQ25\",\n              DQQ21 = \"DQQ21\",\n              ofr = \"DQQ10\",\n              DQQ12 = \"DQQ12\",\n              oveg = \"DQQ7\",\n              DQQ22 = \"DQQ22\",\n              DQQ19 = \"DQQ19\",\n              DQQ16 = \"DQQ16\",\n              DQQ04  = \"DQQ4\",\n              DQQ28 = \"DQQ28\",\n              DQQ26  = \"DQQ26\",\n              DQQ18 = \"DQQ18\",\n              DQQ17 = \"DQQ17\",\n              DQQ08 = \"DQQ8\",\n              DQQ05 = \"DQQ5\",\n              DQQ03 = \"DQQ3\",\n              DQQ02  = \"DQQ2\",\n              DQQ15  = \"DQQ15\"\n)\n\n#Cleaning and exporting ----\nresults$Mean_prevalence &lt;- as.numeric(results$Mean_prevalence)\nresults$Lower_95_CI &lt;- as.numeric(results$Lower_95_CI)\nresults$Upper_95_CI &lt;- as.numeric(results$Upper_95_CI)\n\n\nresults &lt;- results %&gt;%\n  mutate(\n    DQQ_question = as.character(dqqNames[results$Variable]),\n    Variable = as.character(longNames[results$Variable]),\n    Mean_prevalence = case_when(Subgroup == \"Male\" & Variable == \"MDD-W\" ~ NA, .default = Mean_prevalence)\n  ) %&gt;%\n  relocate(DQQ_question, .after = Variable) %&gt;%\n  relocate(Unit, .after = DQQ_question) %&gt;%\n  rename(Indicator = Variable)\n```"
  },
  {
    "objectID": "blog/2024/complex survey design/index.html#exploratory-analysis",
    "href": "blog/2024/complex survey design/index.html#exploratory-analysis",
    "title": "Statistical analysis for weighted data",
    "section": "Exploratory Analysis",
    "text": "Exploratory Analysis\nLets try first exploring the distribution of a food group, for instance NCD-Risk, across two factors, education level and job categories. We set font options for output graphs using showtext package and Whitney font face which has been preferred font for previous DQQ-based graphs.\n\nCode```{r}\n#| output: false\n#| code-fold: true\n#| warning: false\n\nfont_paths(\"font/whitney-2\")\nfont_add(\"Whitney\", \n          regular = \"whitneybook.otf\", \n          bold = \"whitneybold.otf\",\n          italic = \"whitneybookitalic.otf\", \n          bolditalic = \"whitneysemibold.otf\")\nshowtext_auto()\npar(family = \"Whitney\")\n\n# Check for NAs \nsum(is.na(d$ncdr)) # 0\nsum(is.na(d$edu)) # 2\n```\n\n\nIn below graphs distributions of NCD_Risk and NCD-Protect are illustrated using ggplot2 package. Categorical variables are useful for adding extra information on how data distributed, for instance across education, job, region and gender.\n\nCode```{r, fig.width= 12, fig.height= 8, dpi= 96}\n#| fig-cap: \"Distrubution of NCD-Risk\"\n#| code-fold: true\n#| warning: false\n\nd %&gt;%\n  filter(!is.na(edu)) %&gt;%\n  ggplot(aes(x = ncdr, fill = edu)) +\n  geom_histogram(binwidth = 1) +\n  guides(fill = \"none\") +\n  facet_wrap(~edu) + \n  labs(\n    x = \"NCD-Risk values\",\n    y = \"Counts\",\n    title = \"Histogram of NCDR-Risk across education levels\", \n    subtitle = \"Value of one used for binwidth to make bins side-by-side\",\n    caption = \"\"\n  ) +\n  theme(\n    plot.background = element_rect(fill = \"#e9ecef\"), \n    plot.title = element_text(family = \"Whitney\", face = \"bold\", size = 20, margin = margin(t = 0.05, unit = \"cm\")),\n    plot.subtitle = element_text(family = \"Whitney\", face = \"italic\", size = 16, margin = margin(b = 0.5, t = 0.1, unit = \"cm\")),\n    panel.background = element_rect(fill = \"#f8f9fa\", colour = \"gray\"), \n    panel.grid = element_blank(),\n    panel.grid.minor.y = element_line(colour = \"gray\", linetype = 2),\n    panel.grid.major.y = element_line(colour = \"gray\", linetype = 4),\n    axis.title = element_text(family = \"Whitney\", face = \"bold\", size = 12),\n    axis.text = element_text(family = \"Whitney\", face = \"bold\", size = 10),\n    axis.title.x = element_text(family = \"Whitney\", face = \"bold\", size = 12, margin = margin(t = 0.5, unit = \"cm\")),\n    strip.background = element_rect(fill = \"#e9ecef\"),\n    strip.text = element_text(family = \"Whitney\", face= \"bold\", size = 14),\n    plot.margin = margin(t = 0.5, r = 0.5, b = 0.5, l = 0.5, unit = \"cm\")\n  )\n```\n\n\n\nDistrubution of NCD-Risk\n\n\n\n\nCode```{r, fig.width= 12, fig.height= 8, dpi= 96}\n#| fig-cap: \"Distrubution of NCD-Protect\"\n#| code-fold: true\n#| warning: false\n\n# NCD-Protect on gender and regions\nd %&gt;%\n  ggplot(aes(x = ncdp, fill = gender)) +\n  geom_histogram(\n    binwidth = 1, \n    position = \"identity\", \n    alpha = 0.5\n    ) +\n  scale_fill_manual(\n    values = c(\n      \"Male\" = \"#00296b\", \n      \"Female\" = \"#ffd500\"\n      )\n  ) +\n  #guides(fill = \"none\") +\n  facet_wrap(~ reg, nrow = 2, ncol = 3, dir = \"v\") + \n  labs(\n    x = \"NCD-Protect values\",\n    y = \"Counts\",\n    title = \"Histogram of NCD-Protect across region and gender\", \n    subtitle = \"Value of one used for binwidth to make bins side-by-side\",\n    caption = \"\"\n  ) +\n  theme(\n    plot.background = element_rect(fill = \"#e9ecef\"), \n    plot.title = element_text(family = \"Whitney\", face = \"bold\", size = 20, margin = margin(t = 0.05, unit = \"cm\")),\n    plot.subtitle = element_text(family = \"Whitney\", face = \"italic\", size = 16, margin = margin(b = 0.5, t = 0.1, unit = \"cm\")),\n    panel.background = element_rect(fill = \"#f8f9fa\", colour = \"gray\"), \n    panel.grid = element_blank(),\n    panel.grid.minor.y = element_line(colour = \"gray\", linetype = 2),\n    panel.grid.major.y = element_line(colour = \"gray\", linetype = 4),\n    axis.title = element_text(family = \"Whitney\", face = \"bold\", size = 12),\n    axis.text = element_text(family = \"Whitney\", face = \"bold\", size = 10),\n    axis.title.x = element_text(family = \"Whitney\", face = \"bold\", size = 12, margin = margin(t = 0.5, unit = \"cm\")),\n    legend.title = element_blank(),\n    legend.position = c(0.94, 0.92),\n    legend.text = element_text(family = \"Whitney\", face = \"bold\", size = 12),\n    legend.background = element_rect(fill = \"#f8f9fa\"), \n    strip.background = element_rect(fill = \"#e9ecef\"),\n    strip.text = element_text(family = \"Whitney\", face= \"bold\", size = 14),\n    plot.margin = margin(t = 0.5, r = 0.5, b = 0.5, l = 0.5, unit = \"cm\")\n  )\n```\n\n\n\nDistrubution of NCD-Protect\n\n\n\nWe can use results of complex design objects to explore estimated population information based on weighted stratified data. The principal difficulty in designing graphics for complex survey data is representing the sampling weights. Three strategies could be used to overcome this difficulty: 1. Base the graph on an estimated population distribution. 2. Explicitly indicate weights on the graph. 3. Draw a simple random sample from the estimated population distribution and graph this sample instead. Here We start off by extracting some information on mean population estimates NCD_Risk from svyby which compute survey statistics on subsets of a survey defined by factor (education and job). d_w is used as the svydesign object which was defined in previous sections.\nWe can use simple barplot function directly like the first plot, but it would be more effective to retrieve information and save it as data.frame and use ggplot functionality for graphing purposes.\n\nCode```{r, fig.width= 12, fig.height= 8, dpi= 96}\n#| fig-cap: \"Population estimates for male and female\"\n#| code-fold: true\n#| warning: false\n\nbarplot(svymean(~gender, d_w))\n```\n\n\n\nPopulation estimates for male and female\n\n\n\n\nCode```{r, fig.width= 12, fig.height= 8, dpi= 96}\n#| output: false\n#| code-fold: true\n#| warning: false\n\nncdr_job_edu &lt;- svyby(~ncdr, ~edu + job,\n                      svymean,\n                      design = d_w,\n                      keep.names = FALSE\n                      )\n\nncdr_job_edu_df &lt;- data.frame(ncdr_job_edu)\nncdr_job_edu_df$job1 &lt;- cat(str_wrap(ncdr_job_edu_df$job, width = 20))\n```\n\n\n\nCode```{r, fig.width= 12, fig.height= 8, dpi= 96}\n#| fig-cap: \"NCD-Risk mean estimates based on stratified survey data\"\n#| code-fold: true\n#| warning: false\n\nncdr_job_edu_df %&gt;%\n  filter(job != \"Don’t know\") %&gt;%\n  ggplot()+\n  geom_point(aes(x= edu, y= ncdr, color= job, size = 0.5),\n          ) + \n  scale_y_continuous(limits = c(0, 4), expand = c(0.1, 0.1)) +\n  guides(\n    color = \"none\",\n    size = \"none\"\n    ) +\n  facet_wrap(~job) +\n  labs(\n    x = \"Level of completed education\",\n    y = \"NCD-Risk\",\n    title = \"NCD-Risk mean estimates across education and job categories\", \n    caption = \"'Don’t know' responses was removed fom job categories\",\n  ) +\n  theme(\n    plot.background = element_rect(fill = \"#e9ecef\"), \n    plot.title = element_text(family = \"Whitney\", face = \"bold\", size = 20, margin = margin(t = 0.05, b = 1, unit = \"cm\")),\n    plot.caption = element_text(family = \"Whitney\", face = \"italic\", size = 12, margin = margin(t = 0.5, unit = \"cm\"), hjust = 0),\n    panel.background = element_rect(fill = \"#f8f9fa\", colour = \"gray\"), \n    panel.grid = element_blank(),\n    panel.grid.minor.y = element_line(colour = \"gray\", linetype = 2),\n    panel.grid.major.y = element_line(colour = \"gray\", linetype = 4),\n    axis.title.y = element_text(family = \"Whitney\", face = \"bold\", size = 12, margin = margin(r = 0.5, unit = \"cm\")),\n    axis.text.x = element_text(family = \"Whitney\", face = \"bold\", size = 10, angle = 45, hjust = 1),\n    axis.title.x = element_text(family = \"Whitney\", face = \"bold\", size = 12, margin = margin(t = 0.5, unit = \"cm\")),\n    strip.background = element_rect(fill = \"#e9ecef\"),\n    strip.text = element_text(family = \"Whitney\", face= \"bold\", size = 14),\n    plot.margin = margin(t = 0.5, r = 0.5, b = 0.5, l = 0.5, unit = \"cm\")\n  )\n```\n\n\n\nNCD-Risk mean estimates based on stratified survey data"
  },
  {
    "objectID": "blog/2023/LCA sensitivity with true distribution/index.html",
    "href": "blog/2023/LCA sensitivity with true distribution/index.html",
    "title": "Annual or daily average?",
    "section": "",
    "text": "Sensitivity test on LCA output distribution modeled with different input temporal resolutions\n\n\nLife cycle assessment (LCA) is probably the number-one method for assessing environmental performance of an activity, product, or service. There are a couple of good resources if you want to know more about this methodology which I mentioned at the end of this post. But the things that I like to share here are some insights from a study in Journal of Industrial Ecology on uncertainty of the output of the LCA methods driven by variability and granularity of input data.\nOne big challenge of LCA is its inventory characterization step which simply is the process that we take to collect input data to inject to LCA. For instance, electricity consumption in appliance based LCA, and in general as one of the key LCA inputs, is by far the largest contributor to GHG emissions impact category. Now imagine that you want to characterize this parameter for a product like cooking machine, dishwasher, or air-con systems. In most cases, we could find coarse data like annual or monthly average over a large area, like national or provincial level. Though this averaging strategy can significantly affect the LCA output and this is where big data innovations and machine learning can help us.\nThanks to pervasive sensing and Internet of Things (IoT), we can collect data for energy consumption up to minute-by-minute resolution for home appliances. So how this data granularity could improve LCA? It’s simple. By adding more information on true shape or distribution of input parameters like electricity energy consumption. In this paper, authors tried to capture detailed variability of electricity consumption of air conditioners by increasing granularity from annual average down to daily average. And here is the point, they found that replacing annual values with daily ones could reduce almost 80% of uncertainties in the output of the LCA. Put it simply, variability of GHG emission estimates modeled with LCA reduce by 80%. So, this is pretty serious point in LCA modeling of products that use a lot energy in their use-stage and have high variability due to some external factors, like seasonal variability and people behavior which in this context named as interindividual variability.\nYou could see the amount of reduction (or diminishing return) when going from coarse to high granularity. Two important criteria that are used for interpretation of the fit are coefficient of variation CV and contribution to variance CTV which both reduce as we use richer data set for input parameters. You can see the Markov chain simulation result below which simply shows how output variability indicators (CTV and CV) goes down as temporal resolution gets shrunk to daily average.\n\nCode```{r}\n#| code-fold: true\n#| warning: false\n\nlibrary(dplyr)\n\nreadxl::read_excel(\n  path = \"tables/jiec12742-sup-0001-suppmat.xlsx\", \n  sheet = 2, \n  range = \"A69:F75\", \n  col_names = c(\n    \"Statistic\", \n    \"Units\", \n    \"Annual\", \n    \"Monthly\", \n    \"Weekly\", \n    \"Daily\"\n  ), \n  col_types = NULL, \n) %&gt;%\n  gt::gt() %&gt;%\n  gt::tab_header(title = \"Output statistics\", subtitle = gt::md(\"estimated **lifetime greenhouse gas emissions** of air-conditioning systems from stochastic modeling where use-stage electricity consumption (PAC) was aggregated and characterized at different data granularities\")\n  ) %&gt;%\n  gt::tab_spanner(\n    label = \"Data granularity\", \n    columns = c(\"Annual\", \"Monthly\", \"Weekly\", \"Daily\")\n  ) %&gt;%\n  gt::fmt_number(rows = 1:5, decimals = 0, use_seps = T) %&gt;%\n  gt::tab_footnote(\n    footnote = \"Standard deviation\", \n    locations = gt::cells_body(columns = Statistic, rows = 2)\n  ) %&gt;%\n  gt::tab_footnote(\n    footnote = \"Coefficient of variation\", \n    locations = gt::cells_body(columns = Statistic, rows = 6)\n  ) %&gt;%\n  gt::tab_footnote(\n    footnote = \"Contribution to variance\", \n    locations = gt::cells_body(columns = Statistic, rows = 7)\n  ) %&gt;%\n  gt::tab_source_note(source_note = gt::md(\"**Source**: Data from the paper's [supporing information](https://onlinelibrary-wiley-com.proxy3.library.mcgill.ca/action/downloadSupplement?doi=10.1111%2Fjiec.12742&file=jiec12742-sup-0001-SuppMat.xlsx)\")\n  ) %&gt;%\n  gt::tab_style_body(\n    style = list(\n      gt::cell_text(\n      font = gt::google_font(\"Inter\"),\n      color = \"white\"\n    ),\n    gt::cell_fill(color = \"#2a9d8f\"),\n    gt::cell_borders(sides = \"all\", color = \"#264653\", weight = gt::px(4))\n    ), \n    values = c(0.79)\n  )\n```\n\n\n\n\n\n\n\nOutput statistics\n    \n\nestimated lifetime greenhouse gas emissions of air-conditioning systems from stochastic modeling where use-stage electricity consumption (PAC) was aggregated and characterized at different data granularities\n    \n\nStatistic\n      Units\n      \n        Data granularity\n      \n    \n\nAnnual\n      Monthly\n      Weekly\n      Daily\n    \n\n\n\nMean\nkgCO2eq\n20,528\n20,394\n20,430\n20,257\n\n\nSD1\n\nkgCO2eq\n11,739\n8,640\n6,745\n6,604\n\n\nMin\nkgCO2eq\n2,391\n6,271\n9,418\n10,910\n\n\nMax\nkgCO2eq\n94,055\n90,440\n78,861\n84,198\n\n\n95% Range\nkgCO2eq\n36,532\n25,730\n19,592\n19,427\n\n\nCV2\n\ndimensionless\n0.57\n0.42\n0.33\n0.33\n\n\nCTV3\n\ndimensionless\n0.79\n0.40\n0.17\n0.16\n\n\n\n\nSource: Data from the paper’s supporing information\n\n    \n\n\n\n1 Standard deviation\n    \n\n\n2 Coefficient of variation\n    \n\n\n3 Contribution to variance\n    \n\n\n\n\n\nBottom-line: leveraging big data usage in LCA inventory development can significantly reduce uncertainty. This is also the case for energy grid mix as well. Decomposition of energy mix in electricity grid through big, high-resolution data may change our perception on GHG emission and sustainability of a region.\n\n\n\n\n\n\nHere are some useful resources for LCA systems\n\n\n\n\n\nA very good book is Life Cycle Assessment: Theory and Practice if you want to start learning systematically. Couple of useful papers like Recent developments in Life Cycle Assessment, Territorial Life Cycle Assessment (LCA): What exactly is it about? A proposal towards using a common terminology and a research agenda, and Critical review and practical recommendations to integrate the spatial dimension into life cycle assessment."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Ali got his B.S. in Civil Engineering, and his M.S. in Civil and Environmental Engineering. After graduating, he tested designed novel waste technologies to re-use of saline waste to tackle water scarcity and food security in his home country of Iran . Since then, he has shifted away from conventional engineering solutions towards system analysis of the underlying social and political drivers of environmental change.\nHe has experiences as an engineer, researcher, and lately as geospatial data scientist. His current focus is on how human society, specifically urban areas, interact with their environment and metabolize socio-ecological flows and co-evolve."
  },
  {
    "objectID": "about.html#bio",
    "href": "about.html#bio",
    "title": "About",
    "section": "",
    "text": "Ali got his B.S. in Civil Engineering, and his M.S. in Civil and Environmental Engineering. After graduating, he tested designed novel waste technologies to re-use of saline waste to tackle water scarcity and food security in his home country of Iran . Since then, he has shifted away from conventional engineering solutions towards system analysis of the underlying social and political drivers of environmental change.\nHe has experiences as an engineer, researcher, and lately as geospatial data scientist. His current focus is on how human society, specifically urban areas, interact with their environment and metabolize socio-ecological flows and co-evolve."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About",
    "section": "Education",
    "text": "Education\nPhD Bioresource engineering | McGill, Canada | 2023 - 2027\nM.S. Civil and Environmental Engineering | Shahid Beheshti University, Iran | 2015 - 2018\nB.S. Civil Engineering | Kerman University, Iran | 2009 - 2013"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "About",
    "section": "Experience",
    "text": "Experience\nData consultant | Freelance | Global Alliance for Improved Nutrition | Jan 2023 - Present\nData (GIS) Scientist | Full-time | Aurecon | Feb 2023 - May 2023\nSustainability scientist | Freelance | Iran Department of the Environment | Apr 2019 - Apr 2022\nCivil/environmental engineer | Full-time | Dorriz engineering | Feb 2016 - Apr 2022"
  },
  {
    "objectID": "blog/2023/DQQ shiny/index.html",
    "href": "blog/2023/DQQ shiny/index.html",
    "title": "Make your quarto interactive with embedded shiny app",
    "section": "",
    "text": "Short introduction on input data and iframe tag\nI had a project with GAIN which involved data collection, analysis, and visualization. Main inputs were based on survey data came from Gallup World Poll survey and their research partner in Diet Quality Questionnaire project.\n\n\nThe Global Diet Quality Project is a collaboration between Gallup, Harvard Department of Global Health and Population, and the Global Alliance for Improved Nutrition (GAIN).\nThis project aims to collect dietary quality data in the general adult population across countries worldwide, and to provide the tools for valid and feasible diet quality monitoring within countries. The project enables the collection of consistent, comparable dietary data across countries for the first time. source\nHere I want to show you how you could use shiny with all its interactive capabilities inside a quarto document (like the one you’re reading now). The idea is simple, just copy and paste HTML link of your shiny app inside iframe tag which is an inline frame used to embed another document within the current HTML document. You could find more info in this W3school. I just picked two tips and will show you how to apply this method:\n\nTip: Use CSS to style the iframe (see example below).\nTip: It is a good practice to always include a title attribute for the iframe. This is used by screen readers to read out what the content of the iframe is.\nHow to implement\nOk, lets begin: here is my code for shiny app which map diet survey data (analyzed by complex survey design package in R) across the world for 56 countries. You could choose what indicator, or subgroup to choose, but also you can decide on number of discrete colors used for filling the map.\n\nCode```{r}\n#| eval: false\n#| code-fold: true\n#| warning: false\n\nlibrary(readr)\nlibrary(tidyr)\nlibrary(shiny)\nlibrary(sf)\nlibrary(dplyr)\nlibrary(viridis)\nlibrary(showtext)\nlibrary(ggplot2)\nlibrary(purrr)\nlibrary(rnaturalearth)\nlibrary(maps)\n\n\nfont_paths(\"www\")\nfont_add(\"Whitney\", regular = \"whitneybook.otf\", \n           bold = \"whitneybold.otf\",\n           italic = \"whitneybookitalic.otf\", \n           bolditalic = \"whitneysemibold.otf\")\n\nshowtext_auto()\npar(family = \"Whitney\")\n\ndat &lt;- read_csv(\"data/DQQ_GWP_2021-2022_Internal_17Feb2024.csv\")\nshp &lt;- ne_countries(returnclass = \"sf\", scale = 110)\n\ndat2 &lt;-  dat %&gt;%\n  group_by(Country, Indicator, Subgroup) %&gt;%\n  mutate(Mean_prevalence = mean(Mean_prevalence)) %&gt;%\n  distinct(Country, Indicator, Subgroup, .keep_all = T) %&gt;%\n  right_join(shp[ , c(\"geometry\", \"iso_a3\")], by = join_by(ISO3 == iso_a3)) %&gt;%\n  filter(ISO3 != \"ATA\") %&gt;%\n  st_as_sf()\n\n\nui &lt;- bootstrapPage(\n  tags$style(type = \"text/css\", \"html, body {width:100%;height:100%}\"),\n  plotOutput(\"map\", width = \"100%\", height = \"110%\"),\n  tableOutput(\"table\"),\n  absolutePanel(bottom = 10, left = 10, draggable = TRUE, width = \"250px\", height = \"250px\",\n                selectInput(selected = \"All\", label = \"Select a subgroup: \", inputId = \"subgroup\", choices = unique(dat2$Subgroup)),\n                selectInput(selected = \"Fish or seafood\", label = \"Select an indicator\", inputId = \"var\", choices = unique(dat2$Indicator)),\n                sliderInput(inputId = \"quant\", label = \"Select the number of quantiles\", value = 3, min = 3, max = 5)\n  )\n)\n\nserver &lt;- function(input, output, session){\n  \n  dat3 &lt;- reactive({\n    dat2 %&gt;% \n      select(-c(DQQ_question, Difference, Diff_LCI, Diff_UCI, Diff_p)) %&gt;%\n      drop_na() %&gt;%\n      filter(Subgroup == input$subgroup & Indicator == input$var)\n  })\n  \n  quantiles &lt;- reactive({\n    dat3() %&gt;%\n      pull(var = `Mean_prevalence`) %&gt;%\n      quantile(probs = seq(0, 1, length.out = input$quant +1), na.rm = TRUE) %&gt;% \n      as.vector()\n  })\n  \n  labels &lt;- reactive({\n    imap_chr(quantiles(), function(x, idx){\n      return(paste0(round(quantiles()[idx], 0), \"%\", \" – \", round(quantiles()[idx + 1], 0), \"%\"))\n    })\n  })\n  \n  dat4 &lt;- reactive({\n    mylabels &lt;- labels()[1:length(labels()) - 1]\n    dat3() %&gt;%\n      mutate(mean_quantiles = cut(Mean_prevalence,\n                                  breaks = quantiles(),\n                                  labels = mylabels,\n                                  include.lowest = T))\n  })\n  \n  output$map &lt;- renderPlot({\n    global &lt;- map_data('world')\n    global &lt;- global[global$region != \"Antarctica\", ]\n    dat4() %&gt;%\n      ggplot() +\n      geom_polygon(data = global, aes(x=long, y=lat, group = group), fill='NA', color='black', size=0.2) +\n      geom_sf(aes(fill = `mean_quantiles`), color = \"black\", size = 0.5) +\n      scale_fill_viridis(\n        option = \"A\",\n        alpha = 0.9, \n        begin = 0.1, \n        end = 0.9,\n        discrete = T, \n        direction = -1, \n      ) +\n      guides(fill = guide_legend(direction = \"horizontal\",\n                                 label.hjust = 0.5,\n                                 nrow = 1,\n                                 byrow = T,\n                                 reverse = F,\n                                 label.position = \"bottom\",\n                                 keyheight = unit(4, units = \"mm\"),\n                                 keywidth = unit(30, units = \"mm\"))) +\n      labs(x = NULL,\n           y = NULL,\n           title = paste(\"Global map of\", input$var, sep = \" \"),\n           subtitle = paste(\"Global variation of\", input$var, \"indicator\", \"in\", input$subgroup, \"sub-class\", sep = \" \"),\n           caption = \"Map CC-BY-SA; Code:github.com/alirezt\") +\n      \n      theme_minimal() +\n      theme(\n        text = element_text(family = \"Whitney\", face = \"bold\", color = \"black\"),\n        axis.text.x = element_blank(),\n        axis.text.y = element_blank(),\n        plot.background = element_rect(fill = \"#f5f3f4\", color = NA),\n        panel.background = element_rect(fill = \"#f5f3f4\", color = NA),\n        legend.background = element_rect(fill = \"#f5f3f4\", color = NA),\n        legend.position = \"bottom\",\n        plot.margin = unit(c(.5, .5, .2, .5), \"cm\"),\n        legend.title = element_blank(),\n        legend.text = element_text(size = 12, hjust = 0, face = \"bold\", color = \"#4f504b\", family = \"Whitney\"),\n        plot.title = element_text(size = 20, hjust = 0.5, color = \"#4f504b\", family = \"Whitney\"),\n        plot.subtitle = element_text(size = 12, hjust = 0.5, color = \"#4f504b\", \n                                     margin = margin(b = 0.2, t = -0.1, l = 2, unit = \"cm\"), debug = F),\n        plot.caption = element_text(size = 10, hjust = .5, \n                                    margin = margin(t = 0.2, b = 0, unit = \"cm\"), color = \"#939184\")\n      )\n  }) \n  \n}\n\nshinyApp(ui, server)\n```\n\n\nNow, you could publish your app in shinyapps service and copy and paste it like I did here which result in a nice interactive frame filled with your shiny application. Also, as you could see there are bunch of CSS style that I Pandoc div block options as well for designing arrangement and layouting purposes.\n\nNote, as mentioned in quarto docs, you can treat any markdown content you want as a figure by enclosing it in Pandoc div block.\n\n\n\n\n \n\n\n \n\n\n\nHere is the exact code you I used in this quarto file to embed the shiny app.\n&lt;iframe \nid=\"example1\" \nsrc=\"https://alireza-taghdisian.shinyapps.io/dqqshiny_2/\" \nstyle=\"border: none; width: 100%; height: 720px\" \nframeborder=\"0\"&gt;\n&lt;/iframe&gt;\n Also, I used below Pandoc div code for content arrangement.\n::: {.border .column-screen-inset layout=\"[70,-2,28]\"}\n:::"
  },
  {
    "objectID": "blog/2023/Emissions for each pound/index.html",
    "href": "blog/2023/Emissions for each pound/index.html",
    "title": "Embedded emissions for each pound you spend?",
    "section": "",
    "text": "Distributional comparison between two methods for consumption-based emissions calculation in two colors"
  },
  {
    "objectID": "blog/2023/Emissions for each pound/index.html#what-are-the-benefits",
    "href": "blog/2023/Emissions for each pound/index.html#what-are-the-benefits",
    "title": "Embedded emissions for each pound you spend?",
    "section": "What are the benefits?",
    "text": "What are the benefits?\nThey argue that leveraging CF calculators with transaction data have multiple benefits over participatory CF methodologies like survey and physical based methods, such as better representativeness of the population (big data volume vs complex survey design), longitudinal vs snapshot view of carbon emissions, and objective vs self-reported data. They emphasized the significance of regulated and anonymized data donation and transparency from individuals and commercial organizations for the purpose of carbon accounting and climate change policy for the benefits of society."
  },
  {
    "objectID": "blog/2024/camcorder/index.html",
    "href": "blog/2024/camcorder/index.html",
    "title": "How beautiful graphs emerge from simple ones",
    "section": "",
    "text": "In this post I will show you couple of gif examples of ggplot graph development which recorded by camcorder package.\nAs mentioend in their documentation camcorder is an R package to track and automatically save graphics generated with ggplot2 that are created across one or multiple sessions with the eventual goal of creating a GIF showing all the plots saved sequentially during the design process.\nAfter installation, the package enables you to: 1. save a ggplot automatically every time you run ggplot() in any format with given specifications 2. generate a GIF that showcases every step of the design process using those image files 3. inspect the ggplot output directly with your specifications in the RStudio IDE-you’ll get what you see\nI particularly love the third point since it enables you to see the end result instantly instead of saving it with ggsave, for instance.\nHere are some graphs:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnd these are some recorded gif examples:"
  },
  {
    "objectID": "blog/index.html#section",
    "href": "blog/index.html#section",
    "title": "Blog",
    "section": "2024",
    "text": "2024\n\n\n    \n                  \n            March 15, 2024\n        \n        \n            How beautiful graphs emerge from simple ones\n            \n                \n                    r\n                \n                \n                    visualization\n                \n                \n                    ggplot\n                \n                \n                    camcorder\n                \n            \n            Motion picures showing design process of ggplot graphs\n        \n        \n            \n\n    \n    \n                  \n            January 28, 2024\n        \n        \n            Statistical analysis for weighted data\n            \n                \n                    r\n                \n                \n                    survey\n                \n                \n                    weighted data\n                \n                \n                    statistical analysis\n                \n                \n                    visualization\n                \n                \n                    DQQ\n                \n                \n                    GAIN\n                \n            \n            Step by step guidline for extracting statistical information for weighted data using *survey* R package\n        \n        \n            \n\n    \n\n\nNo matching items"
  },
  {
    "objectID": "blog/index.html#section-1",
    "href": "blog/index.html#section-1",
    "title": "Blog",
    "section": "2023",
    "text": "2023\n\n\n    \n                  \n            October 8, 2023\n        \n        \n            Embedded emissions for each pound you spend?\n            \n                \n                    review\n                \n                \n                    jounral of industrial ecology\n                \n                \n                    emission\n                \n                \n                    carbon footprint\n                \n                \n                    carbon multipliers\n                \n                \n                    transaction\n                \n                \n                    income class\n                \n            \n            Using houshold spend data for mapping emissions\n        \n        \n            \n\n    \n    \n                  \n            October 8, 2023\n        \n        \n            Annual or daily average?\n            \n                \n                    review\n                \n                \n                    jounral of industrial ecology\n                \n                \n                    LCA\n                \n                \n                    sensitivity analysis\n                \n                \n                    uncertainty analysis\n                \n                \n                    distrubution\n                \n                \n                    use-stage LCA\n                \n                \n                    markov chain\n                \n                \n                    airconditioning\n                \n            \n            Importance of aggregation level on sensitivity of LCA output\n        \n        \n            \n\n    \n    \n                  \n            May 8, 2023\n        \n        \n            Make your quarto interactive with embedded shiny app\n            \n                \n                    r\n                \n                \n                    shiny\n                \n                \n                    quarto\n                \n                \n                    visualization\n                \n                \n                    interactivity\n                \n                \n                    DQQ\n                \n                \n                    GAIN\n                \n            \n            Use HTML iframe tag to link shiny and quarto\n        \n        \n            \n\n    \n\n\nNo matching items"
  }
]